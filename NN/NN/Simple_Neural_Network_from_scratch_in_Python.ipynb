{
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = ':https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F19%2F420%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240126%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240126T140805Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D76413fb289476b15aee5bc10d78fc00b660695bea7838042cd5491e46e60de674faa69421cba15974b2fce2a7653f70b95be5fe0e02e76286789f4f28d79cd7f545933b859b8ca038fd1984c9ae79e9fad9d852f59b0b5dcdf2a473292b4849ae4d126380f2572134606f9ed4480c57753f19d4a5a4d63850ab6899166bc8c6196fc5859fc9a4648f52c18bbce4dbeaca84d534e9a8d52a4a419c1b6722225c251809e80ea8c9f5746aee7a16f29cdc8e50c80b720da7fd13c77b35e9aa1de98f9599f62d2692aaa9c5ca5e0d87f7b6bcba9f3b695552a71b475002f165e0b124591d41bcfbbe8a433733229fe8bd122a9741d3a1f400563d56a87a31ab59d9d'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "tTmKGapLGXBO"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "11f67844-b20d-474e-856d-9aecd7dd2e8d",
        "_uuid": "a954321b8c2937af9965ded91af4aa8c15343575",
        "id": "o4gU1wyQGXBQ"
      },
      "cell_type": "markdown",
      "source": [
        "<H1>Data analysis and machine learning using custom Neural Network (w/o any scify libraries)</H1>\n",
        "This is my first kernel at Kaggle. I am also a beginner in data science and machine learning.\n",
        "\n",
        "To understand details and advanced concepts in ML, I thought I'll start with simple concepts for my learning or for anyone else in my position.\n",
        "\n",
        "As a result, below is a simple neural network made from scratch in python. I will be updating the text explaining the basics of the network and creating new (and simple) network for different datasets as I go along.\n",
        "\n",
        "Comments/Crits/Corrections welcome. Thanks!"
      ]
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "ee2344ec-7c3f-443f-a3f8-5c82d08e4f0a",
        "_uuid": "9c47d27f4a970f1b38eb009ea3707116241284a1",
        "trusted": true,
        "id": "F1osmkVWGXBR"
      },
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns # visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "374a1d1a-7180-4693-8f64-c835e3aaf6a0",
        "_uuid": "a352d2f170140e15467b2d78486a5e7df71576bf",
        "id": "9k5ylrnpGXBR"
      },
      "cell_type": "markdown",
      "source": [
        "<H2>Load Data</H2>"
      ]
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "b1dd6b67-54f5-41ed-a096-c2e62e83ee87",
        "_uuid": "8867b483cc2f77574aa5d6e20a39861d1ad22d8a",
        "trusted": true,
        "id": "LM9FaRAAGXBR"
      },
      "cell_type": "code",
      "source": [
        "# load iris database\n",
        "data = pd.read_csv('../input/Iris.csv')\n",
        "data.sample(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f4798e56-9a79-499f-904c-ad38915aa89c",
        "_uuid": "032bab9f12b63136364660442700b9912f98a76d",
        "trusted": true,
        "id": "QXyvs682GXBR"
      },
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d9b81a4e-fd03-47b8-bef4-9ad483d7ca87",
        "_uuid": "2b646d0b1df11c98872ebd4b2d5c275734b55769",
        "trusted": true,
        "id": "VHJIlqBAGXBR"
      },
      "cell_type": "code",
      "source": [
        "# simple visualization to show how the inputs compare against each other\n",
        "sns.pairplot( data=data, vars=('SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm'), hue='Species' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "a60e2eff-b5c4-4658-a960-d73df0e220f9",
        "_uuid": "41b39f54acd92bd56a60ffa6d11ef81628c31cd7",
        "id": "pg9BH8NwGXBS"
      },
      "cell_type": "markdown",
      "source": [
        "<H2>Normalize the data</H2>"
      ]
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "454624af-3f92-47e6-9180-c9554782427f",
        "_uuid": "14f46347b268c98a1b04648fe5a0a69e07676e30",
        "trusted": true,
        "id": "C0DjkAREGXBS"
      },
      "cell_type": "code",
      "source": [
        "df_norm = data[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
        "df_norm.sample(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "c24f6f1a-5815-4b92-9c4c-cfe971bdea80",
        "_uuid": "e51e08037742cc51ae6fa01a9c786f6f68fe42db",
        "trusted": true,
        "id": "NmzRmikAGXBS"
      },
      "cell_type": "code",
      "source": [
        "df_norm.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "48edd9b7-741f-4412-a237-89ef77a9e7b2",
        "_uuid": "733a47d4cdb2757a68eb0eae39c35947790a9dac",
        "id": "qlwCUQ7mGXBS"
      },
      "cell_type": "markdown",
      "source": [
        "Convert the Species labels to indexes for use with neural network.<BR>\n",
        "Iris-setoso = 0<BR>\n",
        "Iris-versicolor = 1<BR>\n",
        "Iris-virginica = 2<BR>"
      ]
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "f70e1cb2-52d0-4c78-8168-c973b0a76bf5",
        "_uuid": "ca2dd0087b282cf4c582a451b4d28eadd8ba63f8",
        "trusted": true,
        "id": "iY073nGVGXBS"
      },
      "cell_type": "code",
      "source": [
        "target = data[['Species']].replace(['Iris-setosa','Iris-versicolor','Iris-virginica'],[0,1,2])\n",
        "target.sample(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "47590e72-b402-4316-a8ca-4e3d88c6940b",
        "_uuid": "62bc8543206e1810a449421eb1c3fd6327d0097c",
        "trusted": true,
        "id": "FWJZ488eGXBS"
      },
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_norm, target], axis=1)\n",
        "df.sample(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "3df12ee9-5e43-46bf-aa94-04c659711319",
        "_uuid": "874d7644dcff89441e203f153869afc3b8ff8818",
        "id": "W0BuYyDTGXBT"
      },
      "cell_type": "markdown",
      "source": [
        "<H2>Mark some of the data for testing purpose.</H2>\n",
        "We'll test our network on unseen data."
      ]
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "8affdcdc-e542-4756-a1ad-15c3f1aadb78",
        "_uuid": "07d05b4f875907586d97b92cce4281dfe6a0085c",
        "trusted": true,
        "id": "fGk8CP-5GXBT"
      },
      "cell_type": "code",
      "source": [
        "train_test_per = 90/100.0\n",
        "df['train'] = np.random.rand(len(df)) < train_test_per\n",
        "df.sample(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "20165ffd-19e5-49f6-8de6-5a2d005196a7",
        "_uuid": "9304e29c9ad1609835c92c6d2b2beb46e80739fe",
        "id": "CcLDVUjMGXBT"
      },
      "cell_type": "markdown",
      "source": [
        "<H2>Separate train and test Data</H2>"
      ]
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "a6931b6b-f9dd-4620-ba3d-d70530fbec6b",
        "_uuid": "abeac29a19187a10e5455ca84f93e6f22f1ac182",
        "trusted": true,
        "id": "xW3qi3KcGXBT"
      },
      "cell_type": "code",
      "source": [
        "train = df[df.train == 1]\n",
        "train = train.drop('train', axis=1).sample(frac=1)\n",
        "train.sample(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "3256e1b1-f6b2-4f16-a445-7b1f9d44a8b3",
        "_uuid": "19595835e0b742e9a68e1039b23e32fdf2a073e9",
        "trusted": true,
        "id": "GxVoArAMGXBT"
      },
      "cell_type": "code",
      "source": [
        "test = df[df.train == 0]\n",
        "test = test.drop('train', axis=1)\n",
        "test.sample(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "11444b6c-745f-492b-a65b-9dc041d6f3f3",
        "_uuid": "2d0fc27a78791140e749bcf5e044f277674b704a",
        "trusted": true,
        "id": "_DuQMz_3GXBT"
      },
      "cell_type": "code",
      "source": [
        "X = train.values[:,:4]\n",
        "X[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "aab445d9-9bd8-4bad-a860-2687fb274d7e",
        "_uuid": "1df984211fbc0bb972cb1961963d313883a42461",
        "trusted": true,
        "id": "KCbXV78xGXBT"
      },
      "cell_type": "code",
      "source": [
        "targets = [[1,0,0],[0,1,0],[0,0,1]]\n",
        "y = np.array([targets[int(x)] for x in train.values[:,4:5]])\n",
        "y[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "bc3e0730-244e-4b4b-b26d-23c01d4d9da7",
        "_uuid": "85ba8014cf1bcf3581c450f362b268913a0359b0",
        "id": "HXzUGQ6cGXBT"
      },
      "cell_type": "markdown",
      "source": [
        "<H2>Create backpropagating neural network</H2>\n",
        "Create 3 layers: Input, hidden and Output.\n",
        "\n",
        "Inputs = length and widths of the species<BR>\n",
        "Output = 3 values, each one indicating a species. ie Values 1, 0, 0 for the output indicates Iris-setosa<BR>\n",
        "w1 is a matrices of weight connecting Input and the hidden layer. Each node in input layer connects to each node in the hidden layer.\n",
        "\n",
        "Weight are randomized between -1 and 1."
      ]
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "141ea9e7-5e81-438b-863c-b4ecbdf99112",
        "_uuid": "cf8502b6884e2508abe093f7c2536b2afaf5a98f",
        "trusted": true,
        "id": "Tf44tWxIGXBT"
      },
      "cell_type": "code",
      "source": [
        "num_inputs = len(X[0])\n",
        "hidden_layer_neurons = 5\n",
        "np.random.seed(4)\n",
        "w1 = 2*np.random.random((num_inputs, hidden_layer_neurons)) - 1\n",
        "w1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "1ca5b524-25be-45bd-befc-e6ff5b330c1d",
        "_uuid": "cb15100dd971aefffb12ea6a785f7417f16f846c",
        "id": "ITEE8EPbGXBT"
      },
      "cell_type": "markdown",
      "source": [
        "<H3>w2 are the weights of connections between hidden layer and output layer.</H3>"
      ]
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "f4f382b0-6c3e-4a0b-be6d-e4a3a51ab2d8",
        "_uuid": "f1089894abdf9f9f7e576b55dcb6fde732219436",
        "trusted": true,
        "id": "Ru8jIN0CGXBT"
      },
      "cell_type": "code",
      "source": [
        "num_outputs = len(y[0])\n",
        "w2 = 2*np.random.random((hidden_layer_neurons, num_outputs)) - 1\n",
        "w2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "c4c46877-3ec3-4b1d-a93f-45980e84a408",
        "_uuid": "7a6725dc44f37a087e1c2adfa5c1d0b67bba6220",
        "id": "wnLV06RqGXBT"
      },
      "cell_type": "markdown",
      "source": [
        "<H2>Train the network by updating the weights using backpropogation.</H2>\n",
        "This is the crux of the network. The layers are fed forward using sigmoid activation function. The weighs are then updated based on error using gradient descent.\n",
        "\n",
        "<pre>\n",
        "Forward Propagation ( use current weights to caluculate output ):\n",
        "> node activation = output from previous layer (network inputs in case of first layer) * weights\n",
        "> node output = sigmoid activation function = 1 / ( 1 + exp( node activation ) )\n",
        "\n",
        "Backpropagation ( update network weights ):\n",
        "Error calculation ( how far off we are from the expected values ):\n",
        "> derivative (different for different activation functions) = output * ( 1 - output )\n",
        "> error (for the last layer) = ( expected - output ) * derivative\n",
        "> error (for other layers) = ( error calulated previously * that layer's weight ) * derivative\n",
        "Update weight based on error caculated:\n",
        "> Weight = weight + ( output * error * learning rate )\n",
        "</pre>"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "a2b5bca3-bd4f-4131-b746-51332550d238",
        "_uuid": "7910c728e1633a4c945cd5f5cbc13509953abc12",
        "trusted": true,
        "id": "0ck5ZEshGXBU"
      },
      "cell_type": "code",
      "source": [
        "# taken from> https://gist.github.com/craffel/2d727968c3aaebd10359\n",
        "def draw_neural_net(ax, left, right, bottom, top, layer_sizes):\n",
        "    '''\n",
        "    Draw a neural network cartoon using matplotilb.\n",
        "\n",
        "    :usage:\n",
        "        >>> fig = plt.figure(figsize=(12, 12))\n",
        "        >>> draw_neural_net(fig.gca(), .1, .9, .1, .9, [4, 7, 2])\n",
        "\n",
        "    :parameters:\n",
        "        - ax : matplotlib.axes.AxesSubplot\n",
        "            The axes on which to plot the cartoon (get e.g. by plt.gca())\n",
        "        - left : float\n",
        "            The center of the leftmost node(s) will be placed here\n",
        "        - right : float\n",
        "            The center of the rightmost node(s) will be placed here\n",
        "        - bottom : float\n",
        "            The center of the bottommost node(s) will be placed here\n",
        "        - top : float\n",
        "            The center of the topmost node(s) will be placed here\n",
        "        - layer_sizes : list of int\n",
        "            List of layer sizes, including input and output dimensionality\n",
        "    '''\n",
        "    n_layers = len(layer_sizes)\n",
        "    v_spacing = (top - bottom)/float(max(layer_sizes))\n",
        "    h_spacing = (right - left)/float(len(layer_sizes) - 1)\n",
        "    # Nodes\n",
        "    for n, layer_size in enumerate(layer_sizes):\n",
        "        layer_top = v_spacing*(layer_size - 1)/2. + (top + bottom)/2.\n",
        "        for m in range(layer_size):\n",
        "            circle = plt.Circle((n*h_spacing + left, layer_top - m*v_spacing), v_spacing/4.,\n",
        "                                color='w', ec='k', zorder=4)\n",
        "            ax.add_artist(circle)\n",
        "    # Edges\n",
        "    for n, (layer_size_a, layer_size_b) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
        "        layer_top_a = v_spacing*(layer_size_a - 1)/2. + (top + bottom)/2.\n",
        "        layer_top_b = v_spacing*(layer_size_b - 1)/2. + (top + bottom)/2.\n",
        "        for m in range(layer_size_a):\n",
        "            for o in range(layer_size_b):\n",
        "                line = plt.Line2D([n*h_spacing + left, (n + 1)*h_spacing + left],\n",
        "                                  [layer_top_a - m*v_spacing, layer_top_b - o*v_spacing], c='k')\n",
        "                ax.add_artist(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "db3fb84b-b86a-44a0-aa5f-29f378df7375",
        "_uuid": "4786168c2ad7a8aaf4dd7eb66bd1a71d2dade2c0",
        "id": "VVjKFfnFGXBU"
      },
      "cell_type": "markdown",
      "source": [
        "**A Graphical representations of our network will be something like below**<BR>\n",
        "The first set of 4 nodes is the input.<BR>\n",
        "The second set of 5 nodes is the hidden layer. <BR>\n",
        "The last set of 3 nodes is the output layer.<BR><BR>\n",
        "All the nodes of a layer are fully connected to all nodes of the next layer."
      ]
    },
    {
      "metadata": {
        "_cell_guid": "728c6bfa-bba6-4b90-8f78-ef8a7020ee9c",
        "_uuid": "6a25e5e7217e0164277f4de26c7777a1a59da9d3",
        "trusted": true,
        "id": "wWOOGp_3GXBU"
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(12, 12))\n",
        "ax = fig.gca()\n",
        "ax.axis('off')\n",
        "draw_neural_net(ax, .1, .9, .1, .9, [4, 5, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0fc2cb9e-4bf3-4fff-91c7-cfbf9b2c23f9",
        "_uuid": "3356074e526059ddd552c4692e7150dd10c2df46",
        "id": "u54bco79GXBU"
      },
      "cell_type": "markdown",
      "source": [
        "The sigmoid activation function squashes the input values between 0 and 1. This provides a consistant way for the network to deal with outputs."
      ]
    },
    {
      "metadata": {
        "_cell_guid": "5824165c-ed04-4146-8c79-30f23d6d55c4",
        "_uuid": "4e2fe03a960e36b78dbb247925429e3a45d7a63b",
        "trusted": true,
        "id": "Pp0361jRGXBU"
      },
      "cell_type": "code",
      "source": [
        "# sigmoid function representation\n",
        "_x = np.linspace( -5, 5, 50 )\n",
        "_y = 1 / ( 1 + np.exp( -_x ) )\n",
        "plt.plot( _x, _y )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qZirJGs6GXBU"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "ff67904f-11fd-492d-8991-8a06925208b5",
        "_uuid": "63940deaa9799c624d6b8920e934d3963bda0526",
        "trusted": true,
        "id": "fj5Oc7RaGXBU"
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.2 # slowly update the network\n",
        "error = []\n",
        "for epoch in range(1000):\n",
        "    # activate the first layer using the input\n",
        "    #   matrix multiplication between the input and the layer 1 weights\n",
        "    #   result is fed into a sigmoid function\n",
        "    l1 = 1/(1 + np.exp(-(np.dot(X, w1))))\n",
        "    # activate the second layer using first layer as input\n",
        "    l2 = 1/(1 + np.exp(-(np.dot(l1, w2))))\n",
        "    # find the average errorof this batch\n",
        "    #   using absolute, can use use square as well\n",
        "    er = (abs(y - l2)).mean()\n",
        "    error.append(er)\n",
        "\n",
        "    # BACKPROPAGATION / learning!\n",
        "    # find contribution of error on each weight on the second layer\n",
        "    l2_delta = (y - l2)*(l2 * (1-l2))\n",
        "    # update each weight in the second layer slowly\n",
        "    w2 += l1.T.dot(l2_delta) * learning_rate\n",
        "\n",
        "    # find contribution of error on each weight on the second layer w.r.t the first layer\n",
        "    l1_delta = l2_delta.dot(w2.T) * (l1 * (1-l1))\n",
        "    # udpate weights in the first layer\n",
        "    w1 += X.T.dot(l1_delta) * learning_rate\n",
        "\n",
        "print('Error:', er)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K2Y-DUoSGXBU"
      },
      "cell_type": "markdown",
      "source": [
        "### Plotting Error"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "dWiGT6U0GXBU"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "f15115ce-e27a-4007-af4c-eed3b43dd2ac",
        "_uuid": "e389444888b6439f032841e3607b42703b8a5219",
        "id": "fGtgXAnyGXBU"
      },
      "cell_type": "markdown",
      "source": [
        "<H2>Test the network for accuracy.</H2>\n",
        "Run the network with the updated weights from training."
      ]
    },
    {
      "metadata": {
        "_execution_state": "idle",
        "_cell_guid": "f1b9e52c-3e75-499c-8de2-e9fbf9f9e31d",
        "_uuid": "4250a08db8d0ed17193ec8760f6dbbda1a8ac8bf",
        "trusted": true,
        "id": "35Fad16HGXBU"
      },
      "cell_type": "code",
      "source": [
        "X = test.values[:,:4]\n",
        "y = np.array([targets[int(x)] for x in test.values[:,4:5]])\n",
        "\n",
        "l1 = 1/(1 + np.exp(-(np.dot(X, w1))))\n",
        "l2 = 1/(1 + np.exp(-(np.dot(l1, w2))))\n",
        "\n",
        "np.round(l2,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0cd83a26-b0e7-4be2-8d6e-cf72502ebd1d",
        "_uuid": "782f633989f7b013feb7bbd0417800b51130d1ec",
        "id": "EDiz8FYWGXBV"
      },
      "cell_type": "markdown",
      "source": [
        "From the above maxtrix we take the maximum value (per row), which forms our predictions..."
      ]
    },
    {
      "metadata": {
        "_cell_guid": "02728c67-a8b3-4567-b60f-faa060118b59",
        "_uuid": "796c6ce3d40d175b66284c308486b35ad6e7d3a5",
        "trusted": true,
        "id": "XQEmB1DqGXBV"
      },
      "cell_type": "code",
      "source": [
        "yp = np.argmax(l2, axis=1) # prediction\n",
        "res = yp == np.argmax(y, axis=1)\n",
        "correct = np.sum(res)/len(res)\n",
        "\n",
        "testres = test[['Species']].replace([0,1,2], ['Iris-setosa','Iris-versicolor','Iris-virginica'])\n",
        "\n",
        "testres['Prediction'] = yp\n",
        "testres['Prediction'] = testres['Prediction'].replace([0,1,2], ['Iris-setosa','Iris-versicolor','Iris-virginica'])\n",
        "\n",
        "print(testres)\n",
        "print('Correct:',sum(res),'/',len(res), ':', (correct*100),'%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "HTroc6G7GXBV"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Simple Neural Network from scratch in Python",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}